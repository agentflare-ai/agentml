---
title: "Namespace System"
description: "Extending AgentML functionality through the namespace system with xmlns:prefix directives"
---

# Namespace System

The namespace system is AgentML's mechanism for extending SCXML with custom actions and elements. Namespaces provide modular, reusable components for LLM integration, memory systems, I/O operations, and custom functionality.

## What Are Namespaces?

In AgentML, namespaces extend the base SCXML vocabulary with domain-specific actions. They are declared using the `xmlns:prefix="uri"` directive on the `<agent>` root element:

```xml
<agentml xmlns="github.com/agentflare-ai/agentml"
       datamodel="ecmascript"
       xmlns:gemini="github.com/agentflare-ai/agentml-go/gemini"
       xmlns:memory="github.com/agentflare-ai/agentml-go/memory">

  <state id="processing">
    <onentry>
      <!-- Use Gemini namespace -->
      <gemini:generate
        model="gemini-2.0-flash-exp"
        location="_event"
        promptexpr="'Process: ' + userInput" />

      <!-- Use Memory namespace -->
      <memory:put key="last_input" expr="userInput" />
    </onentry>
  </state>
</agentml>
```

## Namespace URIs

Namespace URIs identify the implementation and version:

### Built-in Namespaces

AgentML provides several official namespaces:

```xml
<agentml xmlns="github.com/agentflare-ai/agentml"
       xmlns:gemini="github.com/agentflare-ai/agentml-go/gemini"
       xmlns:ollama="github.com/agentflare-ai/agentml-go/ollama"
       xmlns:memory="github.com/agentflare-ai/agentml-go/memory"
       xmlns:stdin="github.com/agentflare-ai/agentml-go/stdin">
```

**Official Namespace URIs:**
- `github.com/agentflare-ai/agentml-go/agent` - Core AgentML features (default)
- `github.com/agentflare-ai/agentml-go/gemini` - Google Gemini LLM integration
- `github.com/agentflare-ai/agentml-go/ollama` - Local LLM via Ollama
- `github.com/agentflare-ai/agentml-go/memory` - Vector search and graph database
- `github.com/agentflare-ai/agentml-go/stdin` - Console I/O

### External Schema Namespaces

Import JSON Schema or OpenAPI files:

```xml
<agentml xmlns="github.com/agentflare-ai/agentml"
       xmlns:events="./schemas/events.json"
       xmlns:api="./schemas/openapi.yaml">

  <!-- Reference schemas using JSON Pointer -->
  <transition event="user.message"
              event:schema="events:#/components/schemas/UserMessage"
              target="processing" />
</agentml>
```

## Namespace Prefix Conventions

**Prefix Rules:**
- Must be valid XML NCName (no colons, spaces)
- Use lowercase for consistency
- Choose descriptive names: `gemini`, `memory`, `custom`
- Avoid reserved prefixes: `xml`, `xmlns`

**Good prefixes:**
```xml
xmlns:gemini="..."
xmlns:memory="..."
xmlns:http="..."
xmlns:custom="..."
```

**Avoid:**
```xml
xmlns:ns1="..."  <!-- Not descriptive -->
xmlns:XML="..."  <!-- Reserved -->
xmlns:my-plugin="..."  <!-- Contains hyphen -->
```

## Agent Namespace (Default)

The agent namespace is the default and provides AgentML-specific extensions:

### event:schema Attribute

Schema-guided event validation:

```xml
<agentml xmlns="github.com/agentflare-ai/agentml"
       datamodel="ecmascript">

  <transition event="intent.flight"
              event:schema='{
                "type": "object",
                "properties": {
                  "from": {"type": "string"},
                  "to": {"type": "string"}
                },
                "required": ["from", "to"]
              }'
              target="handle_flight" />
</agentml>
```

### Runtime Snapshots

The agent namespace enables runtime snapshot generation for token-efficient LLM prompts. The runtime automatically generates snapshots containing:

- Current active states
- Datamodel variables
- Available events and their schemas
- Transition conditions

```xml
<agentml xmlns="github.com/agentflare-ai/agentml"
       datamodel="ecmascript">

  <datamodel>
    <data id="from" expr="'NYC'" />
    <data id="to" expr="'Paris'" />
  </datamodel>

  <state id="search_flights">
    <!-- Runtime provides snapshot with datamodel context -->
  </state>
</agentml>
```

## Gemini Namespace

Google Gemini LLM integration:

```xml
<agentml xmlns="github.com/agentflare-ai/agentml"
       xmlns:gemini="github.com/agentflare-ai/agentml-go/gemini">

  <state id="generate">
    <onentry>
      <gemini:generate
        model="gemini-2.0-flash-exp"
        location="_event"
        promptexpr="'You are a helpful assistant. User: ' + userInput" />
    </onentry>

    <transition event="action.response" target="process_response">
      <assign location="response" expr="_event.data.message" />
    </transition>

    <transition event="action.error" target="handle_error" />
  </state>
</agentml>
```

**Gemini Actions:**
- `<gemini:generate>` - Generate text with Gemini models
- `<gemini:stream>` - Stream responses token-by-token

**Attributes:**
- `model` - Model ID (e.g., "gemini-2.0-flash-exp")
- `location` - Variable to store event reference
- `promptexpr` - ECMAScript expression for prompt
- `max-output-tokens` - Limit response length (optional)

## Ollama Namespace

Local LLM integration:

```xml
<agentml xmlns="github.com/agentflare-ai/agentml"
       xmlns:ollama="github.com/agentflare-ai/agentml-go/ollama">

  <state id="classify">
    <onentry>
      <ollama:generate
        model="llama2"
        location="_event"
        promptexpr="'Classify this: ' + userInput" />
    </onentry>

    <transition event="action.response" target="handle_classification" />
  </state>
</agentml>
```

**Ollama Actions:**
- `<ollama:generate>` - Generate with local Ollama model
- `<ollama:stream>` - Stream local model responses

## Memory Namespace

High-performance memory with vector search and graph database, powered by `sqlite-graph`:

```xml
<agentml xmlns="github.com/agentflare-ai/agentml"
       xmlns:memory="github.com/agentflare-ai/agentml-go/memory">

  <state id="store_and_query">
    <onentry>
      <!-- Vector embedding -->
      <memory:embed location="embedding" expr="textContent" />

      <!-- Key-value storage -->
      <memory:put key="user_preference" expr="preferenceValue" />

      <!-- Vector similarity search -->
      <memory:search location="results" expr="queryEmbedding" limit="10" />

      <!-- Graph query with Cypher -->
      <memory:graph-query location="graph_results">
        <query>
          MATCH (p:Person)-[:KNOWS]->(friend)
          WHERE p.age > 25
          RETURN p.name, friend.name
        </query>
      </memory:graph-query>
    </onentry>
  </state>
</agentml>
```

**Memory Actions:**
- `<memory:put>` - Store key-value data
- `<memory:get>` - Retrieve by key
- `<memory:embed>` - Generate vector embeddings
- `<memory:search>` - Vector similarity search
- `<memory:graph-query>` - Execute Cypher queries

All data persists in a single SQLite file with vector and graph capabilities.

## Stdin Namespace

Console I/O for command-line agents:

```xml
<agentml xmlns="github.com/agentflare-ai/agentml"
       xmlns:stdin="github.com/agentflare-ai/agentml-go/stdin">

  <state id="get_input">
    <onentry>
      <stdin:read location="userInput" />
    </onentry>

    <transition event="stdin.received" target="process">
      <assign location="input" expr="_event.data" />
    </transition>
  </state>

  <state id="output">
    <onentry>
      <stdin:write expr="'Bot: ' + response" />
    </onentry>

    <transition target="get_input" />
  </state>
</agentml>
```

**Stdin Actions:**
- `<stdin:read>` - Read from console
- `<stdin:write>` - Write to console

## Creating Custom Namespaces

### Go Implementation (Current)

Currently, custom namespaces are implemented in Go:

**customnamespace/actions.go:**
```go
package customnamespace

import (
    "github.com/agentflare-ai/agentmlx/pkg/scxml"
)

type CustomGenerateAction struct {
    Model    string `xml:"model,attr"`
    Location string `xml:"location,attr"`
    Prompt   string `xml:"promptexpr,attr"`
}

func (a *CustomGenerateAction) Execute(ctx *scxml.Context) error {
    // Process the action
    result := processCustomModel(a.Model, a.Prompt, ctx)

    // Store result in datamodel
    ctx.SetVariable(a.Location, result)

    // Optionally raise an event
    ctx.RaiseEvent("custom.complete", map[string]interface{}{
        "result": result,
    })

    return nil
}

func Register() {
    scxml.RegisterNamespace("github.com/example/custom", map[string]interface{}{
        "generate": &CustomGenerateAction{},
    })
}
```

**Usage in AgentML:**
```xml
<agentml xmlns="github.com/agentflare-ai/agentml"
       xmlns:custom="github.com/example/custom">

  <state id="use_custom">
    <onentry>
      <custom:generate
        model="mymodel"
        location="_event"
        promptexpr="'Process: ' + userInput" />
    </onentry>

    <transition event="custom.complete" target="next_state" />
  </state>
</agentml>
```

### WASM Implementation (Planned)

Future: Implement namespaces in any language via WebAssembly:

**agentml.wit (WebAssembly Interface Types):**
```wit
package agentml:core

interface namespace {
    record context {
        datamodel: string,
        current-state: string,
    }

    record action-params {
        name: string,
        attributes: list<tuple<string, string>>,
        content: string,
        context: context,
    }

    record action-result {
        success: bool,
        events: list<tuple<string, string>>,
        datamodel-updates: list<tuple<string, string>>,
        error: option<string>,
    }

    execute-action: func(params: action-params) -> action-result
}
```

**Rust implementation:**
```rust
wit_bindgen::generate!({
    path: "agentml.wit",
});

struct MyCustomNamespace;

impl Namespace for MyCustomNamespace {
    fn execute_action(params: ActionParams) -> ActionResult {
        // Parse attributes
        let model = params.attributes.iter()
            .find(|(k, _)| k == "model")
            .map(|(_, v)| v.clone())
            .unwrap_or_default();

        // Execute custom logic
        let result = process_with_model(&model, &params.content);

        // Return result with events
        ActionResult {
            success: true,
            events: vec![("custom.complete".to_string(), result.clone())],
            datamodel_updates: vec![("result".to_string(), result)],
            error: None,
        }
    }
}
```

**Load WASM namespace:**
```xml
<agentml xmlns="github.com/agentflare-ai/agentml"
       xmlns:custom="https://cdn.example.com/custom-namespace.wasm">

  <state id="use_wasm">
    <onentry>
      <custom:action model="mymodel" />
    </onentry>
  </state>
</agentml>
```

## Namespace Resolution

The agentmlx runtime resolves namespaces:

1. **Built-in check**: Is URI a built-in namespace?
2. **Local check**: Does URI reference a local file?
3. **Registry check** (planned): Query namespace registry
4. **WASM check** (planned): Is URI a WASM module URL?
5. **Error**: Namespace not found

```bash
# List available namespaces
agentmlx namespace list

# Validate namespace usage
agentmlx validate agent.aml
```

## Namespace Patterns

### Multi-Model Pattern

Use different LLM providers for different tasks:

```xml
<agentml xmlns="github.com/agentflare-ai/agentml"
       xmlns:gemini="github.com/agentflare-ai/agentml-go/gemini"
       xmlns:ollama="github.com/agentflare-ai/agentml-go/ollama">

  <state id="classify">
    <!-- Fast local classification -->
    <onentry>
      <ollama:generate
        model="llama2"
        location="_event"
        promptexpr="'Classify: ' + userInput" />
    </onentry>

    <transition event="action.response"
                cond="_event.data.intent === 'complex'"
                target="detailed_processing" />

    <transition event="action.response" target="simple_processing" />
  </state>

  <state id="detailed_processing">
    <!-- Powerful cloud model for complex tasks -->
    <onentry>
      <gemini:generate
        model="gemini-2.0-flash-exp"
        location="_event"
        promptexpr="'Detailed analysis: ' + userInput" />
    </onentry>
  </state>
</agentml>
```

### Memory-Augmented Generation

Combine LLM with vector search:

```xml
<agentml xmlns="github.com/agentflare-ai/agentml"
       xmlns:gemini="github.com/agentflare-ai/agentml-go/gemini"
       xmlns:memory="github.com/agentflare-ai/agentml-go/memory">

  <state id="answer_question">
    <onentry>
      <!-- Search memory for relevant context -->
      <memory:embed location="query_embedding" expr="userQuestion" />
      <memory:search location="context" expr="query_embedding" limit="5" />

      <!-- Generate with context -->
      <gemini:generate
        model="gemini-2.0-flash-exp"
        location="_event"
        promptexpr="'Answer based on context: ' + JSON.stringify(context) + '\nQuestion: ' + userQuestion" />
    </onentry>

    <transition event="action.response" target="store_answer">
      <assign location="answer" expr="_event.data.message" />
    </transition>
  </state>

  <state id="store_answer">
    <onentry>
      <!-- Store answer for future retrieval -->
      <memory:put key="last_answer" expr="answer" />
    </onentry>
  </state>
</agentml>
```

### I/O Processing Pattern

Combine I/O with LLM processing:

```xml
<agentml xmlns="github.com/agentflare-ai/agentml"
       xmlns:gemini="github.com/agentflare-ai/agentml-go/gemini"
       xmlns:stdin="github.com/agentflare-ai/agentml-go/stdin">

  <state id="interactive">
    <onentry>
      <stdin:write expr="'Bot: How can I help you?'" />
      <stdin:read location="userInput" />
    </onentry>

    <transition event="stdin.received" target="process">
      <assign location="input" expr="_event.data" />
    </transition>
  </state>

  <state id="process">
    <onentry>
      <gemini:generate
        model="gemini-2.0-flash-exp"
        location="_event"
        promptexpr="'User: ' + input" />
    </onentry>

    <transition event="action.response" target="respond">
      <assign location="response" expr="_event.data.message" />
    </transition>
  </state>

  <state id="respond">
    <onentry>
      <stdin:write expr="'Bot: ' + response" />
    </onentry>

    <transition target="interactive" />
  </state>
</agentml>
```

## Best Practices

1. **Use specific URIs**: `github.com/org/project/namespace` not just `custom`
2. **Document your namespace**: Provide clear usage examples and attribute documentation
3. **Follow SCXML patterns**: Use `location` for output, `expr` for input, standard action patterns
4. **Handle errors**: Emit `error.execution.*` events for failures
5. **Version namespaces**: Include version in URI for breaking changes
6. **Test thoroughly**: Unit test all namespace actions
7. **Provide schemas**: Document expected event schemas for namespace actions
8. **Keep actions atomic**: One action should do one thing
9. **Use standard events**: Follow AgentML event naming conventions
10. **Plan for WASM**: Design with future WASM portability in mind

## Namespace Registry (Planned)

Future centralized registry for discovering and installing namespaces:

```bash
# Search for namespaces
agentmlx namespace search stripe

# Install namespace
agentmlx namespace install github.com/community/stripe

# List installed namespaces
agentmlx namespace list

# Update namespace
agentmlx namespace update github.com/community/stripe

# Remove namespace
agentmlx namespace remove github.com/community/stripe
```

## Next Steps

- Learn about [Interpreter](/architecture/interpreter) to understand how namespaces execute
- Explore [I/O Processors](/architecture/io-processors) for external communication
- See [Custom Extensions](/extensions/custom) for creating namespaces
- Read [Namespaces Concept](/concepts/namespaces) for usage patterns
- Review [Memory Extension](/extensions/memory) for sqlite-graph integration
