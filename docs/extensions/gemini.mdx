---
title: "Gemini Extension"
description: "Integrate Google's Gemini models into AgentML agents"
---

# Gemini Extension

The Gemini namespace (`github.com/agentflare-ai/agentml-go/gemini`) integrates Google's Gemini models into AgentML agents, providing powerful cloud-based LLM capabilities.

## Setup

```bash
# Set API key
export GEMINI_API_KEY=your_api_key_here

# Run agent
agentmlx run agent.aml
```

## Basic Usage

```xml
<agentml xmlns="github.com/agentflare-ai/agentml"
       datamodel="ecmascript"
       xmlns:gemini="github.com/agentflare-ai/agentml-go/gemini">

  <datamodel>
    <data id="userInput" expr="''" />
    <data id="response" expr="''" />
  </datamodel>

  <state id="process">
    <onentry>
      <gemini:generate
        model="gemini-2.0-flash-exp"
        location="_event"
        promptexpr="'You are a helpful assistant. User: ' + userInput" />
    </onentry>

    <transition event="action.response" target="complete">
      <assign location="response" expr="_event.data.message" />
    </transition>

    <transition event="action.error" target="error_handler" />
  </state>
</agentml>
```

## Actions

### `<gemini:generate>`

Generate text with Gemini models:

**Attributes:**
- `model` (required) - Model identifier (e.g., "gemini-2.0-flash-exp", "gemini-2.0-exp")
- `location` (required) - Variable to store event  reference
- `promptexpr` (required) - ECMAScript expression for the prompt
- `max-output-tokens` (optional) - Maximum response tokens
- `temperature` (optional) - Sampling temperature (0.0-1.0)

**Events raised:**
- `action.response` - Generation completed successfully
  - `_event.data.message` - Generated text
  - `_event.data.usage` - Token usage information
- `action.error` - Generation failed
  - `_event.data.error` - Error details

## Available Models

### Gemini 2.0 Flash Experimental

Fast, efficient model for most tasks:

```xml
<gemini:generate
  model="gemini-2.0-flash-exp"
  location="_event"
  promptexpr="userQuery" />
```

### Gemini 2.0 Experimental

Most capable model:

```xml
<gemini:generate
  model="gemini-2.0-exp"
  location="_event"
  promptexpr="complexQuery"
  max-output-tokens="2048" />
```

## Generation Parameters

Control generation behavior:

```xml
<agentml xmlns="github.com/agentflare-ai/agentml"
       xmlns:gemini="github.com/agentflare-ai/agentml-go/gemini">

  <state id="generate">
    <onentry>
      <gemini:generate
        model="gemini-2.0-flash-exp"
        location="_event"
        promptexpr="userPrompt"
        temperature="0.7"
        max-output-tokens="1024" />
    </onentry>

    <transition event="action.response" target="success" />
  </state>
</agentml>
```

## Schema-Guided Generation

Combine with `event:schema` for structured outputs:

```xml
<agentml xmlns="github.com/agentflare-ai/agentml"
       xmlns:gemini="github.com/agentflare-ai/agentml-go/gemini">

  <state id="extract_info">
    <onentry>
      <gemini:generate
        model="gemini-2.0-flash-exp"
        location="_event"
        promptexpr="'Extract flight information from: ' + userMessage" />
    </onentry>

    <transition event="action.response"
                event:schema='{
                  "type": "object",
                  "properties": {
                    "from": {"type": "string"},
                    "to": {"type": "string"},
                    "date": {"type": "string", "format": "date"}
                  },
                  "required": ["from", "to", "date"]
                }'
                target="book_flight">
      <assign location="flightData" expr="_event.data" />
    </transition>

    <transition event="error.execution.validation" target="retry_extraction" />
  </state>
</agentml>
```

## Multi-Turn Conversations

Build conversation history in datamodel:

```xml
<agentml xmlns="github.com/agentflare-ai/agentml"
       datamodel="ecmascript"
       xmlns:gemini="github.com/agentflare-ai/agentml-go/gemini">

  <datamodel>
    <data id="conversationHistory" expr="[]" />
  </datamodel>

  <state id="chat">
    <onentry>
      <!-- Add user message to history -->
      <assign location="conversationHistory"
              expr="conversationHistory.concat([{role: 'user', content: userInput}])" />

      <!-- Generate with conversation context -->
      <gemini:generate
        model="gemini-2.0-flash-exp"
        location="_event"
        promptexpr="conversationHistory.map(m => m.role + ': ' + m.content).join('\n')" />
    </onentry>

    <transition event="action.response" target="respond">
      <!-- Add assistant message to history -->
      <assign location="conversationHistory"
              expr="conversationHistory.concat([{role: 'assistant', content: _event.data.message}])" />
    </transition>
  </state>
</agentml>
```

## Error Handling

Handle Gemini-specific errors:

```xml
<agentml xmlns="github.com/agentflare-ai/agentml"
       xmlns:gemini="github.com/agentflare-ai/agentml-go/gemini">

  <datamodel>
    <data id="retryCount" expr="0" />
  </datamodel>

  <state id="generate">
    <onentry>
      <gemini:generate
        model="gemini-2.0-flash-exp"
        location="_event"
        promptexpr="userQuery" />
    </onentry>

    <!-- Success -->
    <transition event="action.response" target="success">
      <assign location="result" expr="_event.data.message" />
    </transition>

    <!-- Rate limit error -->
    <transition event="action.error"
                cond="_event.data.error.type === 'rate_limit'"
                target="rate_limited">
      <log expr="'Rate limited, waiting...'" />
    </transition>

    <!-- Other errors with retry -->
    <transition event="action.error"
                cond="retryCount < 3"
                target="generate">
      <assign location="retryCount" expr="retryCount + 1" />
      <log expr="'Retry attempt ' + retryCount" />
    </transition>

    <!-- Max retries exceeded -->
    <transition event="action.error" target="failed">
      <assign location="error" expr="_event.data.error" />
    </transition>
  </state>

  <state id="rate_limited">
    <onentry>
      <!-- Wait 60 seconds -->
      <send event="retry" target="#_internal" delay="60s" />
    </onentry>

    <transition event="retry" target="generate">
      <assign location="retryCount" expr="0" />
    </transition>
  </state>
</agentml>
```

## Token Usage Tracking

Monitor token consumption:

```xml
<agentml xmlns="github.com/agentflare-ai/agentml"
       xmlns:gemini="github.com/agentflare-ai/agentml-go/gemini">

  <datamodel>
    <data id="totalTokens" expr="0" />
  </datamodel>

  <state id="generate">
    <onentry>
      <gemini:generate
        model="gemini-2.0-flash-exp"
        location="_event"
        promptexpr="query" />
    </onentry>

    <transition event="action.response" target="log_usage">
      <assign location="totalTokens" expr="totalTokens + (_event.data.usage?.total || 0)" />
      <log expr="'Tokens used: ' + _event.data.usage.total" />
      <log expr="'Total session tokens: ' + totalTokens" />
    </transition>
  </state>
</agentml>
```

## Best Practices

1. **Secure API keys**: Use environment variables, never hardcode
2. **Handle rate limits**: Implement exponential backoff
3. **Monitor token usage**: Track costs with usage logging
4. **Use schemas**: Guide output structure with `event:schema`
5. **Validate responses**: Add schema validation for critical data
6. **Set token limits**: Use `max-output-tokens` to control costs
7. **Handle errors gracefully**: Add error transitions for all calls
8. **Choose appropriate models**: Balance capability and cost
9. **Cache when possible**: Store repeated queries in datamodel
10. **Test thoroughly**: Validate behavior across all states

## Command-Line Options

```bash
# Set API key via environment
export GEMINI_API_KEY=your_key
agentmlx run agent.aml

# Or pass directly (not recommended for production)
agentmlx run agent.aml --env GEMINI_API_KEY=your_key

# Enable verbose logging
agentmlx run agent.aml --verbose

# Log token usage
agentmlx run agent.aml --log-tokens
```

## Next Steps

- Learn about [Ollama Extension](/extensions/ollama) for local models
- Explore [Memory Extension](/extensions/memory) for context augmentation
- Read [Token Efficiency](/concepts/token-efficiency) for optimization strategies
- See [Error Handling](/best-practices/error-handling) for robust agents
